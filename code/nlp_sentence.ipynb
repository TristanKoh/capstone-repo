{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conducting basic NLP on sentence and segment level text\n",
    "\n",
    "Some ideas: \n",
    "1. ML model for high frequency practices\n",
    "\n",
    "    a. Non-neural net models as last option (too complex)\n",
    "\n",
    "    b. Experiment with a bunch of sklearn models.\n",
    "\n",
    "2. rule based text models for lowest 10? (after all the focus is about explainability)\n",
    "3. What is the best way to explain? How does that interact with the type of model used?\n",
    "\n",
    "Questions:\n",
    "1. How to test performance? What is the nature of the hold out data? \n",
    "2. How to balance explainability vs performance?\n",
    "\n",
    "    a. Need to add some papers on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "PATH_SENTENCE_TEXT = r\"../dataset/concat_sentence_text.csv\"\n",
    "PATH_SEGMENT_TEXT = r\"../dataset/concat_segment_text.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: NLP on sentence level text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>practice</th>\n",
       "      <th>modality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IP ADDRESS, COOKIES, AND WEB BEACONS</td>\n",
       "      <td>Identifier_Cookie_or_similar_Tech_1stParty</td>\n",
       "      <td>PERFORMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IP ADDRESS, COOKIES, AND WEB BEACONS</td>\n",
       "      <td>Identifier_IP_Address_1stParty</td>\n",
       "      <td>PERFORMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IP addresses will be collected, along with inf...</td>\n",
       "      <td>Identifier_IP_Address_1stParty</td>\n",
       "      <td>PERFORMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The information that our products collect incl...</td>\n",
       "      <td>Identifier_Cookie_or_similar_Tech_1stParty</td>\n",
       "      <td>PERFORMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The information that our products collect incl...</td>\n",
       "      <td>Identifier_IP_Address_1stParty</td>\n",
       "      <td>PERFORMED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence_text  \\\n",
       "0               IP ADDRESS, COOKIES, AND WEB BEACONS   \n",
       "1               IP ADDRESS, COOKIES, AND WEB BEACONS   \n",
       "2  IP addresses will be collected, along with inf...   \n",
       "3  The information that our products collect incl...   \n",
       "4  The information that our products collect incl...   \n",
       "\n",
       "                                     practice   modality  \n",
       "0  Identifier_Cookie_or_similar_Tech_1stParty  PERFORMED  \n",
       "1              Identifier_IP_Address_1stParty  PERFORMED  \n",
       "2              Identifier_IP_Address_1stParty  PERFORMED  \n",
       "3  Identifier_Cookie_or_similar_Tech_1stParty  PERFORMED  \n",
       "4              Identifier_IP_Address_1stParty  PERFORMED  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PATH_SENTENCE_TEXT)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18829 entries, 0 to 18828\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   sentence_text  18829 non-null  object\n",
      " 1   practice       18829 non-null  object\n",
      " 2   modality       18829 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 441.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentence_text\"] = df[\"sentence_text\"].astype(\"string\")\n",
    "df[\"practice\"] = df[\"practice\"].astype(\"category\")\n",
    "df[\"practice\"] = df[\"practice\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18829 entries, 0 to 18828\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   sentence_text  18829 non-null  string  \n",
      " 1   practice       18829 non-null  category\n",
      " 2   modality       18829 non-null  object  \n",
      "dtypes: category(1), object(1), string(1)\n",
      "memory usage: 315.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>practice</th>\n",
       "      <th>modality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IP ADDRESS, COOKIES, AND WEB BEACONS</td>\n",
       "      <td>Identifier_Cookie_or_similar_Tech_1stParty</td>\n",
       "      <td>PERFORMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IP ADDRESS, COOKIES, AND WEB BEACONS</td>\n",
       "      <td>Identifier_IP_Address_1stParty</td>\n",
       "      <td>PERFORMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IP addresses will be collected, along with inf...</td>\n",
       "      <td>Identifier_IP_Address_1stParty</td>\n",
       "      <td>PERFORMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The information that our products collect incl...</td>\n",
       "      <td>Identifier_Cookie_or_similar_Tech_1stParty</td>\n",
       "      <td>PERFORMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The information that our products collect incl...</td>\n",
       "      <td>Identifier_IP_Address_1stParty</td>\n",
       "      <td>PERFORMED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence_text  \\\n",
       "0               IP ADDRESS, COOKIES, AND WEB BEACONS   \n",
       "1               IP ADDRESS, COOKIES, AND WEB BEACONS   \n",
       "2  IP addresses will be collected, along with inf...   \n",
       "3  The information that our products collect incl...   \n",
       "4  The information that our products collect incl...   \n",
       "\n",
       "                                     practice   modality  \n",
       "0  Identifier_Cookie_or_similar_Tech_1stParty  PERFORMED  \n",
       "1              Identifier_IP_Address_1stParty  PERFORMED  \n",
       "2              Identifier_IP_Address_1stParty  PERFORMED  \n",
       "3  Identifier_Cookie_or_similar_Tech_1stParty  PERFORMED  \n",
       "4              Identifier_IP_Address_1stParty  PERFORMED  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Limit to top 5 categories\n",
    "top_5_cats = [\"Identifier_Cookie_or_similar_Tech_1stParty\", \"Contact_E_Mail_Address_1stParty\", \"Location_1stParty\", \"Identifier_Cookie_or_similar_Tech_3rdParty\", \"Identifier_IP_Address_1stParty\"]\n",
    "\n",
    "df = df[df[\"practice\"].isin(top_5_cats)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try first with basic model: TfIDF, with logistic regression, SGDClassifier?\n",
    "\n",
    "### Also todo: To try various word representations and tokenisation. With different stop words? Or n-grams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words={'english'}, ngram_range=(1,4), strip_accents='ascii', binary = True)\n",
    "tfidf_vectors = vectorizer.fit_transform(df[\"sentence_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7982\n",
      "(7982, 218540)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: Number of rows in matrix same as number of sentences.\n",
    "# We have 51747 unique tokens after tokenisation\n",
    "print(len(df))\n",
    "print(tfidf_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split, 20% test size?\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_vectors, df[\"practice\"], test_size = 0.2, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_clf = LogisticRegression(random_state = SEED, max_iter = 500, n_jobs = -1, multi_class = \"ovr\").fit(x_train, y_train)\n",
    "y_pred = logistic_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "           Contact_E_Mail_Address_1stParty       0.66      0.85      0.74       413\n",
      "Identifier_Cookie_or_similar_Tech_1stParty       0.54      0.70      0.61       418\n",
      "Identifier_Cookie_or_similar_Tech_3rdParty       0.47      0.30      0.37       238\n",
      "            Identifier_IP_Address_1stParty       0.56      0.37      0.45       214\n",
      "                         Location_1stParty       0.60      0.45      0.52       314\n",
      "\n",
      "                                  accuracy                           0.59      1597\n",
      "                                 macro avg       0.57      0.53      0.54      1597\n",
      "                              weighted avg       0.58      0.59      0.57      1597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To try visualisation of logistic regression with interpret. At least we know how it works using a simple linear classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sgdclassifier = SGDClassifier(loss = \"hinge\", max_iter = 5000, random_state=SEED, n_jobs = -1).fit(x_train, y_train)\n",
    "y_pred = clf_sgdclassifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "           Contact_E_Mail_Address_1stParty       0.70      0.80      0.75       413\n",
      "Identifier_Cookie_or_similar_Tech_1stParty       0.54      0.59      0.56       418\n",
      "Identifier_Cookie_or_similar_Tech_3rdParty       0.41      0.38      0.39       238\n",
      "            Identifier_IP_Address_1stParty       0.47      0.36      0.41       214\n",
      "                         Location_1stParty       0.56      0.53      0.54       314\n",
      "\n",
      "                                  accuracy                           0.57      1597\n",
      "                                 macro avg       0.54      0.53      0.53      1597\n",
      "                              weighted avg       0.56      0.57      0.56      1597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with LinearSVC (used by the original authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearSVC_clf = SVC(kernel= \"linear\", class_weight=\"balanced\").fit(x_train, y_train)\n",
    "y_pred = linearSVC_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "           Contact_E_Mail_Address_1stParty       0.76      0.77      0.76       413\n",
      "Identifier_Cookie_or_similar_Tech_1stParty       0.59      0.57      0.58       418\n",
      "Identifier_Cookie_or_similar_Tech_3rdParty       0.43      0.45      0.44       238\n",
      "            Identifier_IP_Address_1stParty       0.46      0.48      0.47       214\n",
      "                         Location_1stParty       0.58      0.55      0.56       314\n",
      "\n",
      "                                  accuracy                           0.59      1597\n",
      "                                 macro avg       0.56      0.56      0.56      1597\n",
      "                              weighted avg       0.59      0.59      0.59      1597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_randomforest = RandomForestClassifier(n_jobs = -1, random_state = SEED).fit(x_train, y_train)\n",
    "y_pred = clf_randomforest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "           Contact_E_Mail_Address_1stParty       0.65      0.75      0.70       413\n",
      "Identifier_Cookie_or_similar_Tech_1stParty       0.48      0.57      0.52       418\n",
      "Identifier_Cookie_or_similar_Tech_3rdParty       0.37      0.30      0.33       238\n",
      "            Identifier_IP_Address_1stParty       0.44      0.34      0.38       214\n",
      "                         Location_1stParty       0.52      0.44      0.48       314\n",
      "\n",
      "                                  accuracy                           0.52      1597\n",
      "                                 macro avg       0.49      0.48      0.48      1597\n",
      "                              weighted avg       0.51      0.52      0.51      1597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary (29/8/22): Trying different models using Tfidf yields low performance. \n",
    "The issue should be with feature engineering. Need to look at word embeddings first perhaps, before looking at what models to use.\n",
    "\n",
    "TODO: How does this affect interpret package usage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary (3/9/22): Tried BERT both on all categories and on top 5 categories. Both yield low performance. \n",
    "Might be because not enough training data to train all the parameters.\n",
    "\n",
    "Non-neural networks yield better performance out of the box. \n",
    "So stick to linear models, but at the same time figure out to limit to which categories to predict? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('interpret_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f622adc888634df7afabb8a19e515c6c0448b764a13a8e3831abb14bea24c6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
